{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP1c2PSAU8QFDJRl8sIikD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwkC2CZ66h2o",
        "outputId": "31686c60-7abb-4816-e391-1fa813bbe8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9041\n"
          ]
        }
      ],
      "source": [
        "import numpy as np              # Импортируем библиотеку NumPy для работы с массивами и матрицей\n",
        "from sklearn.datasets import fetch_openml     # Импортируем модуль для загрузки набора данных\n",
        "from sklearn.model_selection import train_test_split  # Модуль для разделения данных на тренировочные и тестовые\n",
        "from sklearn.metrics import accuracy_score      # Модуль для измерения точности модели\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    Класс, представляющий однослойный перцептрон.\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.25, epochs=5):\n",
        "        \"\"\"\n",
        "        Конструктор класса, инициализирующий параметры модели.\n",
        "\n",
        "        :param learning_rate: Скорость обучения (по умолчанию 0.01)\n",
        "        :param epochs: Количество эпох обучения (по умолчанию 100)\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate       # Сохраняем значение скорости обучения\n",
        "        self.epochs = epochs                     # Сохраняем количество эпох обучения\n",
        "        self.weights = None                      # Начальные веса будут установлены позже\n",
        "        self.bias = None                         # Смещение будет установлено позже\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Реализация сигмоидальной функции активации.\n",
        "\n",
        "        :param x: Входной вектор или скаляр\n",
        "        :return: Значение сигмоиды от x\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))             # Формула сигмоидной функции\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        \"\"\"\n",
        "        Реализация производной сигмоидальной функции.\n",
        "\n",
        "        :param x: Входной вектор или скаляр\n",
        "        :return: Значение производной сигмоиды от x\n",
        "        \"\"\"\n",
        "        sig = self.sigmoid(x)                    # Сначала находим значение сигмоиды\n",
        "        return sig * (1 - sig)                   # Производная сигмоиды\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Функция для предсказания классов на основе текущих весов и смещений.\n",
        "\n",
        "        :param X: Матрица входных данных (признаки)\n",
        "        :return: Вектор предсказанных классов (0 или 1)\n",
        "        \"\"\"\n",
        "        linear_output = np.dot(X, self.weights) + self.bias   # Линейный выход = сумма произведений весов и признаков плюс смещение\n",
        "        probabilities = self.sigmoid(linear_output)           # Применяем сигмоидальную активацию к линейному выходу\n",
        "        return (probabilities >= 0.5).astype(int)             # Возвращаем классы: 1, если вероятность больше 0.5, иначе 0\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Обучающая функция модели.\n",
        "\n",
        "        :param X_train: Тренировочная матрица признаков\n",
        "        :param y_train: Тренировочные метки классов\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X_train.shape          # Определяем количество образцов и признаков\n",
        "\n",
        "        # Инициализация весов и смещения нулями\n",
        "        self.weights = np.zeros(n_features)            # Весов столько же, сколько признаков\n",
        "        self.bias = 1                                  # Смещение - это один элемент\n",
        "\n",
        "        for epoch in range(self.epochs):               # Проходимся по заданному количеству эпох\n",
        "            # Вычисляем линейный выход для каждого образца\n",
        "            linear_output = np.dot(X_train, self.weights) + self.bias\n",
        "\n",
        "            # Применяем сигмоидальную активацию к линейному выходу\n",
        "            predicted = self.sigmoid(linear_output)\n",
        "\n",
        "            # Вычисляем ошибку между предсказанными значениями и истинными классами\n",
        "            error = y_train - predicted\n",
        "\n",
        "            # Вычисляем градиенты для весов и смещения\n",
        "            dw = (1 / n_samples) * np.dot(X_train.T, error * self.sigmoid_derivative(linear_output))\n",
        "            db = (1 / n_samples) * np.sum(error * self.sigmoid_derivative(linear_output))\n",
        "\n",
        "            # Обновляем веса и смещение согласно градиентам и скорости обучения\n",
        "            self.weights += self.learning_rate * dw\n",
        "            self.bias += self.learning_rate * db\n",
        "\n",
        "# Загружаем датасет MNIST\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)   # Загружаем данные MNIST\n",
        "\n",
        "# Преобразуем метки в бинарные (цифры 0 против всех остальных)\n",
        "y_binary = (y != '0').astype(int)                             # 0 заменяется на 0, другие цифры на 1\n",
        "\n",
        "# Делиим данные на тренировочные и тестовые наборы\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42)              # 20% данных отводится на тестовый набор\n",
        "\n",
        "# Нормализуем данные (масштабируем пиксельные значения от 0 до 1)\n",
        "X_train = X_train / 255.0                                     # Делим каждый пиксель на 255 (максимальное значение)\n",
        "X_test = X_test / 255.0                                       # То же самое делаем для тестового набора\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "perceptron = Perceptron()                                      # Создаем экземпляр класса Perceptron\n",
        "perceptron.fit(X_train, y_train)                              # Запускаем обучение модели\n",
        "\n",
        "# Прогнозируем результаты на тестовых данных\n",
        "predictions = perceptron.predict(X_test)                       # Получаем предсказанные классы\n",
        "\n",
        "# Оцениваем точность модели\n",
        "accuracy = accuracy_score(y_test, predictions)                 # Сравниваем реальные метки с предсказаниями\n",
        "print(f'Accuracy: {accuracy:.4f}')                            # Выводим точность модели с точностью до четырех знаков"
      ]
    }
  ]
}