{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbpUarJZ0E3h0QiSU0T14B"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdpieJ6xVRPi",
        "outputId": "7559d09a-1c80-4372-84db-9a1247e00fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1/5:\n",
            "Эпоха 2/5:\n",
            "Эпоха 3/5:\n",
            "Эпоха 4/5:\n",
            "Эпоха 5/5:\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np              # Импортируем библиотеку NumPy для работы с массивами и матрицей\n",
        "from sklearn.datasets import fetch_openml     # Импортируем модуль для загрузки набора данных\n",
        "from sklearn.model_selection import train_test_split  # Модуль для разделения данных на тренировочные и тестовые\n",
        "from sklearn.metrics import accuracy_score      # Модуль для измерения точности модели\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    Класс, представляющий однослойный перцептрон.\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.25, epochs=5):\n",
        "        \"\"\"\n",
        "        Конструктор класса, инициализирующий параметры модели.\n",
        "\n",
        "        :param learning_rate: Скорость обучения (по умолчанию 0.25)\n",
        "        :param epochs: Количество эпох обучения (по умолчанию 5)\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate       # Сохраняем значение скорости обучения\n",
        "        self.epochs = epochs                     # Сохраняем количество эпох обучения\n",
        "        self.weights = None                      # Начальные веса будут установлены позже\n",
        "        self.bias = None                         # Смещение будет установлено позже\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Реализация сигмоидальной функции активации.\n",
        "\n",
        "        :param x: Входной вектор или скаляр\n",
        "        :return: Значение сигмоиды от x\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))             # Формула сигмоидной функции\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        \"\"\"\n",
        "        Реализация производной сигмоидальной функции.\n",
        "\n",
        "        :param x: Входной вектор или скаляр\n",
        "        :return: Значение производной сигмоиды от x\n",
        "        \"\"\"\n",
        "        sig = self.sigmoid(x)                    # Сначала находим значение сигмоиды\n",
        "        return sig * (1 - sig)                   # Производная сигмоиды\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Функция для предсказания классов на основе текущих весов и смещений.\n",
        "\n",
        "        :param X: Матрица входных данных (признаки)\n",
        "        :return: Вектор предсказанных классов (0 или 1)\n",
        "        \"\"\"\n",
        "        linear_output = np.dot(X, self.weights) + self.bias   # Линейный выход = сумма произведений весов и признаков плюс смещение\n",
        "        probabilities = self.sigmoid(linear_output)           # Применяем сигмоидальную активацию к линейному выходу\n",
        "        return (probabilities >= 0.5).astype(int)             # Возвращаем классы: 1, если вероятность больше 0.5, иначе 0\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Обучающая функция модели с применением алгоритма положительного и отрицательного подкрепления.\n",
        "\n",
        "        :param X_train: Тренировочная матрица признаков\n",
        "        :param y_train: Тренировочные метки классов\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X_train.shape          # Определяем количество образцов и признаков\n",
        "\n",
        "        # Инициализация весов и смещения случайными значениями\n",
        "        self.weights = np.random.normal(size=n_features)  # Инициализация весов нормальным распределением\n",
        "        self.bias = np.random.normal()                   # Инициализация смещения случайным числом\n",
        "\n",
        "        for epoch in range(self.epochs):               # Проходимся по заданному количеству эпох\n",
        "            print(f'Эпоха {epoch + 1}/{self.epochs}:')\n",
        "\n",
        "            # Перемешиваем данные перед каждым проходом\n",
        "            idx = np.arange(n_samples)                 # Индексируем образцы\n",
        "            np.random.shuffle(idx)                     # Перемешиваем индексы\n",
        "            X_shuffled = X_train[idx]                  # Смешанный набор данных\n",
        "            y_shuffled = y_train[idx]                  # Соответствующие смешанные метки\n",
        "\n",
        "            for xi, yi in zip(X_shuffled, y_shuffled):  # Для каждого образца в перемешанном наборе\n",
        "                output = self.sigmoid(np.dot(xi, self.weights) + self.bias)  # Вычисляем выход нейрона\n",
        "                error = yi - output                                    # Ошибка (целевое значение минус предсказанное)\n",
        "\n",
        "                # Если ошибка положительная (персептрон недооценил значение), применяем положительное подкрепление\n",
        "                if error > 0:\n",
        "                    # Усиливаем веса и смещение пропорционально величине ошибки\n",
        "                    self.weights += self.learning_rate * error * xi\n",
        "                    self.bias += self.learning_rate * error\n",
        "                elif error < 0:\n",
        "                    # Если ошибка отрицательная (персептрон переоценил значение), применяем отрицательное подкрепление\n",
        "                    # Ослабляем веса и смещение пропорционально величине ошибки\n",
        "                    self.weights -= self.learning_rate * abs(error) * xi\n",
        "                    self.bias -= self.learning_rate * abs(error)\n",
        "                else:\n",
        "                    # Если ошибка равна нулю, ничего не меняем\n",
        "                    pass\n",
        "\n",
        "# Загружаем датасет MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X = mnist['data']\n",
        "y = mnist['target'].astype(np.int8)\n",
        "\n",
        "# Преобразовываем данные в Numpy-массивы\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "# Преобразуем метки в бинарные (цифры 0 против всех остальных)\n",
        "y_binary = (y != '0').astype(int)                             # 0 заменяется на 0, другие цифры на 1\n",
        "\n",
        "# Делиим данные на тренировочные и тестовые наборы\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42)              # 20% данных отводится на тестовый набор\n",
        "\n",
        "# Нормализуем данные (масштабируем пиксельные значения от 0 до 1)\n",
        "X_train = X_train / 255.0                                     # Делим каждый пиксель на 255 (максимальное значение)\n",
        "X_test = X_test / 255.0                                       # То же самое делаем для тестового набора\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "perceptron = Perceptron()                                      # Создаем экземпляр класса Perceptron\n",
        "perceptron.fit(X_train, y_train)                              # Запускаем обучение модели\n",
        "\n",
        "# Прогнозируем результаты на тестовых данных\n",
        "predictions = perceptron.predict(X_test)                       # Получаем предсказанные классы\n",
        "\n",
        "# Оцениваем точность модели\n",
        "accuracy = accuracy_score(y_test, predictions)                 # Сравниваем реальные метки с предсказаниями\n",
        "print(f'Accuracy: {accuracy:.4f}')                            # Выводим точность модели с точностью до четырех знаков"
      ]
    }
  ]
}