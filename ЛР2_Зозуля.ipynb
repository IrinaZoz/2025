{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN//rhyP2QkOOc6D55VFPGT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdpieJ6xVRPi",
        "outputId": "234cc0f1-7d4b-48f7-e8d7-a1502bc8e3d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1/25:\n",
            "Эпоха 2/25:\n",
            "Эпоха 3/25:\n",
            "Эпоха 4/25:\n",
            "Эпоха 5/25:\n",
            "Эпоха 6/25:\n",
            "Эпоха 7/25:\n",
            "Эпоха 8/25:\n",
            "Эпоха 9/25:\n",
            "Эпоха 10/25:\n",
            "Эпоха 11/25:\n",
            "Эпоха 12/25:\n",
            "Эпоха 13/25:\n",
            "Эпоха 14/25:\n",
            "Эпоха 15/25:\n",
            "Эпоха 16/25:\n",
            "Эпоха 17/25:\n",
            "Эпоха 18/25:\n",
            "Эпоха 19/25:\n",
            "Эпоха 20/25:\n",
            "Эпоха 21/25:\n",
            "Эпоха 22/25:\n",
            "Эпоха 23/25:\n",
            "Эпоха 24/25:\n",
            "Эпоха 25/25:\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np  # Импортируем библиотеку NumPy для работы с массивами и матрицей\n",
        "from sklearn.datasets import fetch_openml  # Импортируем модуль для загрузки набора данных\n",
        "from sklearn.model_selection import train_test_split  # Модуль для разделения данных на тренировочные и тестовые\n",
        "from sklearn.metrics import accuracy_score  # Модуль для измерения точности модели\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    Класс, представляющий однослойный перцептрон.\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.25, epochs=25):\n",
        "        \"\"\"\n",
        "        Конструктор класса, инициализирующий параметры модели.\n",
        "\n",
        "        :param learning_rate: Скорость обучения\n",
        "        :param epochs: Количество эпох обучения\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate  # Сохраняем значение скорости обучения\n",
        "        self.epochs = epochs  # Сохраняем количество эпох обучения\n",
        "        self.weights = None  # Начальные веса будут установлены позже\n",
        "        self.bias = None  # Смещение будет установлено позже\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Реализация сигмоидальной функции активации.\n",
        "\n",
        "        :param x: Входной вектор или скаляр\n",
        "        :return: Значение сигмоиды от x\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))  # Формула сигмоидной функции\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Функция для предсказания классов на основе текущих весов и смещений.\n",
        "\n",
        "        :param X: Матрица входных данных (признаки)\n",
        "        :return: Вектор предсказанных классов (0 или 1)\n",
        "        \"\"\"\n",
        "        linear_output = np.dot(X, self.weights) + self.bias  # Линейный выход = сумма произведений весов и признаков плюс смещение\n",
        "        probabilities = self.sigmoid(linear_output)  # Применяем сигмоидальную активацию к линейному выходу\n",
        "        return (probabilities >= 0.5).astype(int)  # Возвращаем классы: 1, если вероятность больше 0.5, иначе 0\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Обучающая функция модели с применением алгоритма положительного и отрицательного подкрепления.\n",
        "\n",
        "        :param X_train: Тренировочная матрица признаков\n",
        "        :param y_train: Тренировочные метки классов\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X_train.shape  # Определяем количество образцов и признаков\n",
        "\n",
        "        # Инициализация весов и смещения случайными значениями\n",
        "        self.weights = np.random.normal(size=n_features)  # Инициализация весов нормальным распределением\n",
        "        self.bias = np.random.normal()  # Инициализация смещения случайным числом\n",
        "\n",
        "        for epoch in range(self.epochs):  # Проходимся по заданному количеству эпох\n",
        "            print(f'Эпоха {epoch + 1}/{self.epochs}:')  # Выводим номер текущей эпохи\n",
        "\n",
        "            # Перемешиваем данные перед каждым проходом\n",
        "            idx = np.arange(n_samples)  # Индексируем образцы\n",
        "            np.random.shuffle(idx)  # Перемешиваем индексы\n",
        "            X_shuffled = X_train[idx]  # Смешанный набор данных\n",
        "            y_shuffled = y_train[idx]  # Соответствующие смешанные метки\n",
        "\n",
        "            for xi, yi in zip(X_shuffled, y_shuffled):  # Для каждого образца в перемешанном наборе\n",
        "                output = self.sigmoid(np.dot(xi, self.weights) + self.bias)  # Вычисляем выход нейрона\n",
        "                error = yi - output  # Ошибка (целевое значение минус предсказанное)\n",
        "\n",
        "                # Если ошибка положительная (персептрон недооценил значение), применяем положительное подкрепление\n",
        "                if error > 0:\n",
        "                    # Усиливаем веса и смещение пропорционально величине ошибки\n",
        "                    self.weights += self.learning_rate * error * xi\n",
        "                    self.bias += self.learning_rate * error\n",
        "                elif error < 0:\n",
        "                    # Если ошибка отрицательная (персептрон переоценил значение), применяем отрицательное подкрепление\n",
        "                    # Ослабляем веса и смещение пропорционально величине ошибки\n",
        "                    self.weights -= self.learning_rate * abs(error) * xi\n",
        "                    self.bias -= self.learning_rate * abs(error)\n",
        "                else:\n",
        "                    # Если ошибка равна нулю, ничего не меняем\n",
        "                    pass\n",
        "\n",
        "# Загружаем датасет MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)  # Загружаем данные MNIST\n",
        "X = mnist['data']  # Извлекаем данные изображений (векторизованные пиксели)\n",
        "y = mnist['target'].astype(np.int8)  # Извлекаем метки классов (цифры от 0 до 9)\n",
        "\n",
        "# Преобразовываем данные в Numpy-массивы\n",
        "X = X.to_numpy()  # Преобразуем данные изображений в Numpy-массив\n",
        "y = y.to_numpy()  # Преобразуем метки в Numpy-массив\n",
        "\n",
        "# Преобразуем метки в бинарные (цифры 0 против всех остальных)\n",
        "y_binary = (y != '0').astype(int)  # 0 заменяется на 0, другие цифры на 1\n",
        "\n",
        "# Делиим данные на тренировочные и тестовые наборы\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42)  # 20% данных отводится на тестовый набор\n",
        "\n",
        "# Нормализуем данные (масштабируем пиксельные значения от 0 до 1)\n",
        "X_train = X_train / 255.0  # Делим каждый пиксель на 255 (максимальное значение)\n",
        "X_test = X_test / 255.0  # То же самое делаем для тестового набора\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "perceptron = Perceptron()  # Создаем экземпляр класса Perceptron\n",
        "perceptron.fit(X_train, y_train)  # Запускаем обучение модели\n",
        "\n",
        "# Прогнозируем результаты на тестовых данных\n",
        "predictions = perceptron.predict(X_test)  # Получаем предсказанные классы\n",
        "\n",
        "# Оцениваем точность модели\n",
        "accuracy = accuracy_score(y_test, predictions)  # Сравниваем реальные метки с предсказаниями\n",
        "print(f'Accuracy: {accuracy:.4f}')  # Выводим точность модели с точностью до четырех знаков"
      ]
    }
  ]
}